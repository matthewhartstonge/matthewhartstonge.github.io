[{"content":"Terraform Plugin Framework Custom Types One of the great new things the Terraform Plugin Framework provides is a stronger focus on strict typing and with that, the ability to develop custom types.\nOne of the first issues I discovered straight out of the gate when attempting to build a new Terraform Provider with the Plugin Framework was that the data I was modelling for a resource used UUIDs for its record ids. I quickly tried to reach for an equivalent UUID validator in the plugin framework. Unfortunately, the UUID validator hasn\u0026rsquo;t been brought across from SDKv2. Remembering the benefits the Plugin Framework was supposed to afford us, I started to dig into the custom types.\nWhen I initially dug into custom types, the Framework was only at v0.14.X and coming back to it almost a year later with the Framework having gone Generally Available (GA) with v1.X.X in February of 2023, there were several improvements and interfaces I needed to update my custom UUID type to use.\nSidenote: Shout out to Brian Flad (bflad) who initially created a custom type for time values while building out the Plugin Framework to see how the interface would look for implementors.\nInterface-Driven Design The Framework now provides a core-type system that can be extended, which makes a lot more sense and makes fantastic use of Go\u0026rsquo;s composability to reduce the amount of code required. Pre-v1.X.X types were simply tfsdk Attributes that would then take in your custom type:\n\u0026#34;id\u0026#34;: tfsdk.Attribute{ Required: true, Type: uuidtypes.UUIDType{}, // Potentially previous Validators } But now custom types are extended from the Framework\u0026rsquo;s base types, which roughly match the underlying base types that Go (the programming language) provides, so my UUID Type now implements basetypes.StringTypable.\n\u0026#34;id\u0026#34;: schema.StringAttribute{ CustomType: uuidtypes.UUIDType{}, Required: true, // ... }, Surprisingly, once I worked out the new interfaces that were required to implement a basetypes.StringTypable, I was able to remove a lot of my code and migrate the remaining methods to wrap the overloaded methods where my custom type (UUIDType or UUIDValue) was required to be specified.\nMaintenance Take the following method that implements the attr.Attribute interface that overloads Equal from the composed basetypes.StringType struct.\n// Equal returns true if the two types are equivalent. func (u UUIDType) Equal(o attr.Type) bool { other, ok := o.(UUIDType) if !ok { return false } return u.StringType.Equal(other.StringType) } While a trivial example of how the new Plugin Framework\u0026rsquo;s composition helps, this means that as the framework grows and new features and methods get added to the base String Type, the maintenance overhead required should be minimised as the base types will, hopefully in most cases, be able to implement upgraded functionality for us for free.\nRolling up from v0.14.X to v1.X.X, while expected, was a bit of a pain as I was developing on top of a beta framework with many underlying changes expected - Custom Types being one of the last features of the framework to get a look at. In truth, custom types weren\u0026rsquo;t documented and supported until Terraform Plugin Framework v1.3.X. The new documentation is fantastic, enabling a developer to easily integrate and extend the Plugin Framework.\nFollow Along Feel free to follow along with my development at GitHub or chat via my socials:\nGithub - matthewhartstonge/terraform-provider-fusionauth Github - matthewhartstonge/terraform-plugin-framework-type-uuid LinkedIn Twitter Addendum Time to Code: 6h Time to Blog: 1.5h ","permalink":"https://blog.mykro.co.nz/posts/2023-07-22-devlog-002/","summary":"Terraform Plugin Framework Custom Types One of the great new things the Terraform Plugin Framework provides is a stronger focus on strict typing and with that, the ability to develop custom types.\nOne of the first issues I discovered straight out of the gate when attempting to build a new Terraform Provider with the Plugin Framework was that the data I was modelling for a resource used UUIDs for its record ids.","title":"Devlog: 002 - Building Terraform Custom Types"},{"content":"Terraform If you\u0026rsquo;ve been living under a rock or happen to be a newcomer in the DevOps/Site Reliability Engineering space, Hashicorp\u0026rsquo;s Terraform enables provisioning and managing cloud infrastructure. It\u0026rsquo;s essentially a glorified diffing tool for any cloud resource that, as long as a Terraform Provider exists, can ensure the state of your infrastructure is as expected when written in Hashicorp Config Language (HCL).\nAs a forewarning before digging deeper, it has been common to hear some Linuxy sysadmin-looking neckbeards in-passing talking about infrastructure as code, better known as IaC, being the bee\u0026rsquo;s knees and how they keep managing to give Dave a good ribbing after causing the Great Network failure of \u0026lsquo;22 after performing a Git force push\u0026hellip;\nTerraform could be your new life.\nIt\u0026rsquo;s a good one.\nI digress\u0026hellip;\nThe great thing about Terraform is that it provides for your infrastructure:\nAutomated creation of new resources Showing the difference between current and expected resources on terraform plan The ability to reconcile the current state with the written expectation on terraform apply And when used with Git, an auditable history of changes Plenty of Terraform Providers exist for cloud providers, for example, Azure, AWS, Digital Ocean and more! But while Terraform can manage Cloud Resources, it has been built so that, as long as you can interact with an API (create, read, update or delete) to adjust the state of a given \u0026ldquo;Thing\u0026rdquo;, it can be managed by Terraform.\nProviders Hashicorp has maintained a wonderfully extensible Terraform Plugin Software Development Kit (SDK) for creating Providers for many, many years and has recently journeyed into what it would look like to build an idiomatically Go, more streamlined, strongly typed framework with documentation generation for creating providers. If you want to dig into the weeds to understand the difference between the Plugin SDKv2 and the Plugin Framework, check out Hashicorp\u0026rsquo;s article on the \u0026ldquo;Plugin Framework Benefits\u0026rdquo;.\nObjectives At my place of employment, we have been using FusionAuth as our 3rd-party auth provider and a community-maintained Terraform Provider, which I have committed and pushed many a PR to. While it works, there are several rough edges that would be nice to round out, plus I wanted to gain an appreciation of where Hashicorp is heading with the new framework.\nMy main objectives when starting this project are:\nConsistency - Ensuring that the project has a similar consistent pattern of solving common problems. DX/UX - Ensure it provides a much better developer and user experience due to automatic documentation generation or better error suggestions. Testability - Ensuring that the project has proper acceptance tests that show when the API of FusionAuth or the Go-Client has broken the Terraform Provider. Starting Out Hashicorp kindly provides many good resources for creating your first Terraform Provider. The first thing I read through was Hashicorp\u0026rsquo;s documentation on Plugin Development. I then cloned the Terraform Provider Scaffolding Framework repo and proceeded to get myself versed in the repo\u0026rsquo;s layout.\nInterestingly, the Provider implementation is stored in an internal folder, meaning external developers can\u0026rsquo;t import the Provider code. Not a bad thing, but it helps to force developers to use the Terraform Provider as a gRPC binary plugin assuming they don\u0026rsquo;t want to copy+paste code.\nDelving into internal/provider/provider.go I started to build out my FusionAuth Provider config - enabling the configuration of a Host Name and API Token.\nAfter an initial skeleton, I backtracked to the docs and found a helpful walkthrough article on framework-based Providers. The info gleaned here helped with initial provider configuration - using envvars and pulling data out from the config struct was pertinent to success. So that was neat to find.\nfunc (p *FusionAuthProvider) Configure(ctx context.Context, req provider.ConfigureRequest, resp *provider.ConfigureResponse) { // Check environment variables apiToken := os.Getenv(envApiToken) endpoint := os.Getenv(envEndpoint) tenant := os.Getenv(envTenant) var data FusionAuthProviderModel // Read configuration data into model resp.Diagnostics.Append(req.Config.Get(ctx, \u0026amp;data)...) if resp.Diagnostics.HasError() { return } // Configuration values are now available. if data.ApiToken.String() != \u0026#34;\u0026#34; { apiToken = data.ApiToken.String() } if apiToken == \u0026#34;\u0026#34; { resp.Diagnostics.AddError( \u0026#34;Missing API Token Configuration\u0026#34;, \u0026#34;While configuring the provider, the API token was not found in \u0026#34;+ \u0026#34;the \u0026#34;+envApiToken+\u0026#34; environment variable or provider \u0026#34;+ \u0026#34;configuration block api_token attribute.\u0026#34;, ) } if data.Endpoint.String() != \u0026#34;\u0026#34; { endpoint = data.Endpoint.String() } if endpoint == \u0026#34;\u0026#34; { resp.Diagnostics.AddError( \u0026#34;Missing Endpoint Configuration\u0026#34;, \u0026#34;While configuring the provider, the API endpoint was not found in \u0026#34;+ \u0026#34;the \u0026#34;+envEndpoint+\u0026#34; environment variable or provider \u0026#34;+ \u0026#34;configuration block endpoint attribute.\u0026#34;, ) } if data.Tenant.String() != \u0026#34;\u0026#34; { tenant = data.Tenant.String() } baseURL, err := url.Parse(endpoint) if err != nil { resp.Diagnostics.AddError( \u0026#34;Unable to parse FusionAuth API Endpoint\u0026#34;, \u0026#34;While configuring the provider, the API endpoint \u0026#39;\u0026#34;+endpoint+\u0026#34;\u0026#39;was unable \u0026#34;+ \u0026#34;to be parsed as a URL.\u0026#34;, ) } // Finalized validating config, return errors if resp.Diagnostics.HasError() { return } // client configuration for data sources and resources httpClient := \u0026amp;http.Client{ Timeout: time.Second * 10, } client := FusionAuthClient{ API: fusionauth.NewClient(httpClient, baseURL, apiToken), Tenant: tenant, } // Bind in the client data resp.DataSourceData = client resp.ResourceData = client } Refer: https://github.com/matthewhartstonge/terraform-provider-fusionauth/blob/95cb893c5bb5e778a1af18592d0719e4492e732f/internal/provider/provider.go#L83-L153\nInterestingly, I don\u0026rsquo;t know if I\u0026rsquo;m meant to be plugging in a struct to resp.DataSourceData and resp.ResourceData as the \u0026ldquo;client\u0026rdquo; as that bit wasn\u0026rsquo;t clear, but no doubt I\u0026rsquo;ll find this out pretty quick when I crack back into this when building out my first Terraform FusionAuth Resource.\nAnywho, that\u0026rsquo;s where I got to for my first night.\nFollow along Feel free to follow along with my development at GitHub or chat via my socials:\nGithub - matthewhartstonge/terraform-provider-fusionauth LinkedIn Twitter Addendum Time to Code: 3h Time to Blog: 2h Realising I can plumb thumbnails into my blogs and backporting: 1h ","permalink":"https://blog.mykro.co.nz/posts/2023-07-12-devlog-001/","summary":"Terraform If you\u0026rsquo;ve been living under a rock or happen to be a newcomer in the DevOps/Site Reliability Engineering space, Hashicorp\u0026rsquo;s Terraform enables provisioning and managing cloud infrastructure. It\u0026rsquo;s essentially a glorified diffing tool for any cloud resource that, as long as a Terraform Provider exists, can ensure the state of your infrastructure is as expected when written in Hashicorp Config Language (HCL).\nAs a forewarning before digging deeper, it has been common to hear some Linuxy sysadmin-looking neckbeards in-passing talking about infrastructure as code, better known as IaC, being the bee\u0026rsquo;s knees and how they keep managing to give Dave a good ribbing after causing the Great Network failure of \u0026lsquo;22 after performing a Git force push\u0026hellip;","title":"Devlog: 001 - Building Terraform Providers"},{"content":"Take the following Go code as an example:\npackage main type CodeType int const ( CodeA CodeType = iota + 10 CodeB ) func calculateCodes(codeType CodeType) int { var value int if codeType == CodeA { value = 10 } else { value = 20 } return value } func main() { fmt.Println(calculateCodes(CodeA)) } Why is else evil? There are a number of things that can cause an issue as code gets maintained over its lifecycle which can be dangerous:\nWe‚Äôve already allocated memory by declaring the variable, therefore, what should its default be if no condition is met?\nvalue has been declared without an underlying value - generally this could lead to introducing undefined/null in the system especially when working with pointers. Nulls can lead to undefined or unexpected behaviour depending on the following conditionals or worse‚Ä¶ panics can occur due to nil pointer dereferencing where we‚Äôve expected a value. If we decide at some point to change the value of CodeA we may now have unintentional behaviour happening in the system where we fall into the else case when we shouldn‚Äôt.\nThis could easily be missed in PR as the else case may be a long way away therefore not visible in the review window. else leads to developer memory overhead\nGenerally humans can only hold 5¬±2 items in memory An else adds +1 things to remember, so if we can remove it, we can hold more important things üòâ How do we fix this? Be explicit about our expected default values Use conditions as explicit conditions and/or guard statements - ‚Äúif something, do this‚Äù not ‚ÄúIf something do this, but uhh sometimes this‚Äù Use shortcut returns which will help lead to flat and sparsely indented code. What would we change to fix it? Original Code Just for a quick recap‚Ä¶\nfunc calculateCodes(codeType CodeType) int { var value int if codeType == CodeA { value = 10 } else { value = 20 } return value } Use explicit defaults and conditions\nfunc calculateCodes(codeType CodeType) int { value := 20 if codeType == CodeA { value = 10 } return value } Use explicit defaults, conditions and guarding/shortcut returns\nfunc calculateCodes(codeType CodeType) int { if codeType == CodeA { return 10 } return 20 } Caveats There are definitely places where we can‚Äôt get away without using an else statement for example calling expensive functions and that‚Äôs okay. In 99% of cases it should be possible to remove an else statement.\nfunc calculateLateness(code CodeType, isLate bool) int64 { if isLate == True { expensiveFunc(code) } else { expensiveOtherFunc(code) } } If this path is deep within a function maybe we could return early at this point, or potentially this path could be a good candidate for being refactored out into its own function:\nfunc calculateLateness(code CodeType, isLate bool) int64 { if isLate { return expensiveFunc(code) } return expensiveOtherFunc(code) } Final Thoughts If we consider else to be mid we can save ourselves from else ladders and potential undefined/unexpected outcomes in future.\nTake it easy out their developers üëå\nAddendum Time to blog: 2h ","permalink":"https://blog.mykro.co.nz/posts/2023-05-30-else-is-evil/","summary":"Take the following Go code as an example:\npackage main type CodeType int const ( CodeA CodeType = iota + 10 CodeB ) func calculateCodes(codeType CodeType) int { var value int if codeType == CodeA { value = 10 } else { value = 20 } return value } func main() { fmt.Println(calculateCodes(CodeA)) } Why is else evil? There are a number of things that can cause an issue as code gets maintained over its lifecycle which can be dangerous:","title":"Else Is Evil"},{"content":"TL;DR Assuming you\u0026rsquo;ve already got your reverse proxy running, in wp-config.php add the following:\n\u0026lt;?php /** TLS/HTTPS fixes **/ // in some setups HTTP_X_FORWARDED_PROTO might contain a comma-separated list // e.g. http,https so check for https existence. if (strpos($_SERVER[\u0026#39;HTTP_X_FORWARDED_PROTO\u0026#39;], \u0026#39;https\u0026#39;) !== false) { // update HTTPS server variable to always \u0026#39;pretend\u0026#39; incoming requests were // performed via the HTTPS protocol. $_SERVER[\u0026#39;HTTPS\u0026#39;]=\u0026#39;on\u0026#39;; } If you\u0026rsquo;re getting desperate:\n// If you ever get stuck, you can override the database set site URIs as well. define( \u0026#39;WP_HOME\u0026#39;, \u0026#39;https://example.com\u0026#39; ); define( \u0026#39;WP_SITEURL\u0026#39;, \u0026#39;https://example.com\u0026#39; ); // FORCE_SSL_ADMIN is for when you want to secure logins and the admin area so // that both passwords and cookies are never sent in the clear. define( \u0026#39;FORCE_SSL_ADMIN\u0026#39;, true ); Introduction If you are using a reverse proxy that performs SSL termination for you, you may find yourself in a redirect loop or getting a lot of mixed content as Wordpress, quite rightly, acts as if it\u0026rsquo;s a normal HTTP request.\nPHP uses server variables[1] that scripts can hook into to learn about their world. One of these magic variables, $_SERVER['HTTPS'], is set to a non-empty value if the script was queried through the HTTPS protocol.\nWordpress uses this variable ($_SERVER['HTTPS']) to detect if an incoming request should mutate links, hence leading to a nasty redirect loop when behind a reverse proxy with SSL termination.\n‚ö†Ô∏è Warning! There are a lot of example configuration files ahead!\nArchitecture Overview In order to fix it, we can programmatically make use of that standardised X-Forwarded-Proto header that can be forwarded via a proxy pass configuration in nginx, so we need to configure a few things. In this configuration we have the following architecture:\n+---------------------------+ | | | +-----------+ | | | Varnish | | | +--^----+---+ | | | | | +---------------+ | | | | | Client | | +--+----v-+ | | +--------\u0026gt;| Nginx | | | („Éé‡≤† ‚à©‡≤†)„ÉéÂΩ° | | +-------+-+ | +---------------+ | | | | | | | +--------v----+ | | | Wordpress | | | +-------------+ | | | | („Å•ÔΩ°‚óï‚Äø‚Äø‚óïÔΩ°)„Å• server | | | +---------------------------+ client -\u0026gt; Nginx (https) -\u0026gt; Varnish --(on cache miss)--\u0026gt; Nginx (http) -\u0026gt; wordpress client -\u0026gt; Nginx (https) -\u0026gt; Varnish (on cache hit) nginx (https) -\u0026gt; varnish configuration This configures the client-\u0026gt;varnish flow using SSL termination, but setting a number of X-Forwarded-* headers that we can use to pick up on.\n// /etc/nginx/conf.d/example.com.https.conf # nginx (TLS termination) -\u0026gt; varnish cache server { listen 443 ssl; listen [::]:443 ssl; ## Your website name goes here e.g. example.com *.example.com server_name example.com; server_name_in_redirect off; port_in_redirect off; ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem; include /etc/letsencrypt/options-ssl-nginx.conf; ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; location / { proxy_pass http://varnish; proxy_set_header Host $http_host; proxy_set_header HTTPS \u0026#34;on\u0026#34;; proxy_set_header X-Forwarded-Host $http_host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto https; proxy_set_header X-Forwarded-Port 443; proxy_set_header X-Real-IP $remote_addr; } } upstream varnish { server varnish:80; } varnish -\u0026gt; nginx (http) configuration Thanks to Linode[2] for the reference implementation (which has been extended to add a X-Cache header for tracking cache hits).\n// default.vcl vcl 4.0; sub vcl_hit { set req.http.X-Cache = \u0026#34;hit\u0026#34;; } sub vcl_miss { set req.http.X-Cache = \u0026#34;miss\u0026#34;; } sub vcl_pass { set req.http.X-Cache = \u0026#34;pass\u0026#34;; } sub vcl_pipe { set req.http.X-Cache = \u0026#34;pipe uncacheable\u0026#34;; } // Specify that the backend (nginx) is listening on port 8080. // This is our internal backend route to wordpress. backend default { .host = \u0026#34;nginx\u0026#34;; .port = \u0026#34;8080\u0026#34;; } // Allow cache-purging requests only from the following hosts. acl purger { \u0026#34;localhost\u0026#34;; \u0026#34;127.0.0.1\u0026#34;; } sub vcl_recv { unset req.http.X-Cache; // Allow cache-purging requests only from the IP addresses in the above acl purger. // If a purge request comes from a different IP address, an error message will be produced. if (req.method == \u0026#34;PURGE\u0026#34;) { if (!client.ip ~ purger) { return(synth(405, \u0026#34;This IP is not allowed to send PURGE requests.\u0026#34;)); } return (purge); } // Change the X-Forwarded-For header if (req.restarts == 0) { if (req.http.X-Forwarded-For) { set req.http.X-Forwarded-For = client.ip; } } // Exclude POST requests or those with basic authentication from caching if (req.http.Authorization || req.method == \u0026#34;POST\u0026#34;) { return (pass); } // Exclude RSS feeds from caching if (req.url ~ \u0026#34;/feed\u0026#34;) { return (pass); } // Don\u0026#39;t cache the WordPress admin and login pages: if (req.url ~ \u0026#34;wp-admin|wp-login\u0026#34;) { return (pass); } // Remove has_js and CloudFlare/Google Analytics __* cookies and statcounter is_unique set req.http.Cookie = regsuball(req.http.Cookie, \u0026#34;(^|;\\s*)(_[_a-z]+|has_js|is_unique)=[^;]*\u0026#34;, \u0026#34;\u0026#34;); // Remove a \u0026#34;;\u0026#34; prefix, if present. set req.http.Cookie = regsub(req.http.Cookie, \u0026#34;^;\\s*\u0026#34;, \u0026#34;\u0026#34;); // WordPress sets many cookies that are safe to ignore. set req.http.cookie = regsuball(req.http.cookie, \u0026#34;wp-settings-\\d+=[^;]+(; )?\u0026#34;, \u0026#34;\u0026#34;); set req.http.cookie = regsuball(req.http.cookie, \u0026#34;wp-settings-time-\\d+=[^;]+(; )?\u0026#34;, \u0026#34;\u0026#34;); set req.http.Cookie = regsuball(req.http.Cookie, \u0026#34;wordpress_test_cookie=[^;]+(; )?\u0026#34;, \u0026#34;\u0026#34;); if (req.http.cookie == \u0026#34;\u0026#34;) { unset req.http.cookie; } } // Cache-purging for a particular page must occur each time we make edits // to that page. sub vcl_purge { set req.method = \u0026#34;GET\u0026#34;; set req.http.X-Purger = \u0026#34;Purged\u0026#34;; return (restart); } // The sub vcl_backend_response directive is used to handle communication // with the backend server, nginx. We use it to set the amount of time // the content remains in the cache. // We can also set a grace period, which determines how Varnish will serve // content from the cache even if the backend server is down. // - Time can be set in seconds (s), minutes (m), hours (h) or days (d). // Here, we‚Äôve set the caching time to 24 hours, and the grace period to // 1 hour, but you can adjust these settings based on your needs. sub vcl_backend_response { set beresp.ttl = 24h; set beresp.grace = 1h; if (bereq.url !~ \u0026#34;wp-admin|wp-login|product|cart|checkout|my-account|/?remove_item=\u0026#34;) { unset beresp.http.set-cookie; } } // Change the headers for purge requests. sub vcl_deliver { if (req.http.X-Purger) { set resp.http.X-Purger = req.http.X-Purger; } if (obj.uncacheable) { set req.http.X-Cache = req.http.X-Cache + \u0026#34; uncacheable\u0026#34; ; } else { set req.http.X-Cache = req.http.X-Cache + \u0026#34; cached\u0026#34; ; } // set X-Cache header in response set resp.http.X-Cache = req.http.X-Cache; } nginx (http) -\u0026gt; wordpress configuration Here we use a generic nginx+php-fpm fastcgi_pass configuration.\n// /etc/nginx/conf.d/example.com.http.conf # nginx (TLS termination) -\u0026gt; varnish cache -\u0026gt; nginx http -\u0026gt; php-fpm server { listen 8080; listen [::]:8080; server_name example.com; server_name_in_redirect off; port_in_redirect off; access_log /var/log/nginx/example.com/access.log; error_log /var/log/nginx/example.com/error.log info; ## Your only path reference. root /var/www/example.com; location = /favicon.ico { log_not_found off; access_log off; } location = /robots.txt { allow all; log_not_found off; access_log off; } # deny running scripts inside writable directories location ~* /(images|cache|media|logs|tmp)/.*\\.(php|pl|py|jsp|asp|sh|cgi)$ { return 403; error_page 403 /403_error.html; } location / { # This is cool because no php is touched for static content. # include the \u0026#34;?$args\u0026#34; part so non-default permalinks doesn\u0026#39;t break when using query string try_files $uri $uri/ /index.php?$is_args$query_string; } location ~ \\.php$ { try_files $uri =404; fastcgi_split_path_info ^(.+\\.php)(/.+)$; fastcgi_intercept_errors on; #NOTE: You should have \u0026#34;cgi.fix_pathinfo = 0;\u0026#34; in php.ini include /etc/nginx/fastcgi.conf; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_pass php-fpm; } location ~* \\.(js|css|png|jpg|jpeg|gif|ico)$ { expires max; log_not_found off; } } upstream php-fpm { server php-fpm:9000; } Forcing \u0026lsquo;Faux\u0026rsquo;TTPS for PHP (wp-config.php configuration) Woo! Now we have all the above bootstrapped, we can finally grab the X-Forwarded-Proto header that\u0026rsquo;s been passed along, and force PHP to think that $_SERVER['HTTPS'] = 'on'; by creating an override in wp-config.php[3]\n// wp-config.php \u0026lt;?php /** TLS/HTTPS fixes **/ // in some setups HTTP_X_FORWARDED_PROTO might contain a comma-separated list // e.g. http,https so check for https existence. if (strpos($_SERVER[\u0026#39;HTTP_X_FORWARDED_PROTO\u0026#39;], \u0026#39;https\u0026#39;) !== false) { // update HTTPS server variable to always \u0026#39;pretend\u0026#39; incoming requests were // performed via the HTTPS protocol. $_SERVER[\u0026#39;HTTPS\u0026#39;]=\u0026#39;on\u0026#39;; } If you get stuck, or redirects are still happening, you can use the site variables to revert to HTTP, or enforce an HTTPS root uri, which will override the database configuration:\n// wp-config.php // If you ever get stuck, you can override the database set site URIs as well. define( \u0026#39;WP_HOME\u0026#39;, \u0026#39;https://example.com\u0026#39; ); define( \u0026#39;WP_SITEURL\u0026#39;, \u0026#39;https://example.com\u0026#39; ); Lastly, you can enforce that admin must be visited over HTTPS (FauxTTPS?) by setting FORCE_SSL_ADMIN[4] to stop bad actors trying to jump in over HTTP\u0026hellip; ¬Ø\\_(„ÉÑ)_/¬Ø\n// wp-config.php // FORCE_SSL_ADMIN is for when you want to secure logins and the admin area so // that both passwords and cookies are never sent in the clear. define( \u0026#39;FORCE_SSL_ADMIN\u0026#39;, true ); Addendum ASCII chart created by: asciiflow Time to SSL Termination frustration: 7+ hours Time to Blog: 1h:39m ","permalink":"https://blog.mykro.co.nz/posts/2020-07-06-nginx-varnish-wordpress-ssl-termination/","summary":"TL;DR Assuming you\u0026rsquo;ve already got your reverse proxy running, in wp-config.php add the following:\n\u0026lt;?php /** TLS/HTTPS fixes **/ // in some setups HTTP_X_FORWARDED_PROTO might contain a comma-separated list // e.g. http,https so check for https existence. if (strpos($_SERVER[\u0026#39;HTTP_X_FORWARDED_PROTO\u0026#39;], \u0026#39;https\u0026#39;) !== false) { // update HTTPS server variable to always \u0026#39;pretend\u0026#39; incoming requests were // performed via the HTTPS protocol. $_SERVER[\u0026#39;HTTPS\u0026#39;]=\u0026#39;on\u0026#39;; } If you\u0026rsquo;re getting desperate:\n// If you ever get stuck, you can override the database set site URIs as well.","title":"Nginx, Varnish and Wordpress with SSL Termination"},{"content":"Introduction WordPress is clearly one of the world\u0026rsquo;s most used Content Management Systems (CMS) commanding over 35% of the internet, and over 60% of the CMS market [1].\nWorking in Operations (ops), you see your fair share of friends, family and businesses that ask you to set up a WordPress site as their go to blogging platform. This really comes down to WordPress\u0026rsquo; ease of use, massive library of themes and it\u0026rsquo;s modular nature that enables the extension of it\u0026rsquo;s core via the use of plugins.\nAfter hearing one of my clients wanting to move forward with another WordPress site, I thought it was a good time to investigate PHP 7.2/.3/.4, clean up my docker-compose stack and experiment with different caching technologies in order to make it load as fast as possible for end-users.\nScience! üß™ Initially my WordPress deployment comprised of MySQL, php-fpm (PHP FastCGI Process Manager), and nginx with no caching optimizations. In order to work out if the optimizations were actually doing anything, I needed to gain a baseline benchmark using my current stack. Luckily, since everything was composed via docker, this was very easy to do.\nMethod In order to keep the variables under control the following hardware and software was used across all benchmark tests:\nHardware:\nMac Book Pro 2011 CPU: Intel¬Æ Core‚Ñ¢ i7-2720QM CPU @ 2.20GHz √ó 8 RAM: 3.8GiB OS: Ubuntu 18.04.4 64-bit Software:\nWordPress version 5.3.2 NGINX version 1.16.1 MariaDB version 10.4.12 Docker 19.03.8 Docker Compose v1.25.4 Hey v0.1.3 [2]. ~ Shameless Self Promotion ~\nstackme [3] - to provide a base docker-compose stack to get WordPress up and running. PHP Configurations:\nphp-fpm 7.2.28 php-fpm 7.2.28 + opcache php-fpm 7.2.28 + opcache + varnish cache php-fpm 7.2.28 + opcache + w3 total cache plugin php-fpm 7.2.28 + opcache + w3 total cache plugin + varnish cache php-fpm 7.3.15 php-fpm 7.3.15 + opcache php-fpm 7.3.15 + opcache + varnish cache php-fpm 7.3.15 + opcache + w3 total cache plugin php-fpm 7.3.15 + opcache + w3 total cache plugin + varnish cache php-fpm 7.4.3 php-fpm 7.4.3 + opcache php-fpm 7.4.3 + opcache + varnish cache php-fpm 7.4.3 + opcache + w3 total cache plugin php-fpm 7.4.3 + opcache + w3 total cache plugin + varnish cache I decided to opt for hey as the choice of benchmark tool, as it\u0026rsquo;s similar to the apache benchmark tool (ab), but more modern, capable of using multiple cpus.\nOur default benchmark will be run using the following configuration:\nhey -z 60s -o csv http://localhost:80 This configures hey to flood the WordPress server for 60 seconds with requests, with a default of 50 worker threads.\nHypothesis PHP by itself will be the slowest PHP with OpCache should provide minor performance boosts PHP with w3TotalCache should be pretty performant, but will be limited by PHP. PHP with Varnish should be the fastest, as it doesn\u0026rsquo;t have to hit PHP after initial page render. Results One thing I was surprised about was how much of a difference OpCache made in terms of processor usage and the impact that had to response time. I guess it shows how much overhead the interpreter can cause. (check out the screenshots under extras for nerds)\nHaving used other languages such as Python [4], and Java [5] I was somewhat surprised that PHP\u0026rsquo;s OpCache wasn\u0026rsquo;t added until 2012. That\u0026rsquo;s only 8 years ago\u0026hellip;\nThe other compounding issue with OpCache is that, while it has been bundled with PHP since version 5.5 [6], it may not be enabled by default depending on where you get the binary from, or if your php.ini file hasn\u0026rsquo;t set opcache.enable=1. So make sure to enable this if you can!\nLastly, my hypothesis about Varnish turned out to be correct, but I did find that having W3TotalCache enabled as well added extra overhead, so you probably don\u0026rsquo;t need to use both.\nfig 1. PHP Response Times and PHP With OpCache Enabled, without caching. fig 2. PHP With OpCache Enabled, with different caching strategies fig 3. Requests per Second, with different caching strategies Conclusion/TL;DR Where possible, always run PHP with OpCache enabled. If you can\u0026rsquo;t run varnish, enable w3TotalCache - it\u0026rsquo;s pretty damn performant. For best performance, run with varnish. Last Thoughts and Disclaimers This benchmark runs with the best performance you can get out of WordPress. It\u0026rsquo;s a fresh installation with no other plugins enabled. This enabled testing of the underlying technologies - therefore mileage may vary depending on how many plugins you have enabled on your WordPress site.\nI found to get the best out of W3TotalCache a lot of settings had to be tweaked to get it to work for anything other than the main/front page. So do experiment to ensure you get the best you can out of it.\nIn this benchmark, W3TotalCache was configured to make use of PHP\u0026rsquo;s Alternative PHP Cache (APC) for object caching. APC provides an in memory caching API that developers can use.\nCertain default Caching technologies may not work well for sites that make use of backend processing on the fly. That said, if your WordPress site uses JavaScript to update the loaded page and API calls, you should be safe. In any case it\u0026rsquo;s best to run a test site introducing your caching technology before fully rolling it out.\nExtras for Nerds \u0026lsquo;Sup Nerds. Check out some extra graphs around system stats and overall performance with max response times.\nBenchmark repository including benchmark scripts, the raw data and database.\nMoar Response Time Graphs fig 4. Performance across all variants fig 5. PHP With OpCache Enabled, with different caching strategies, including Maximum Response time System Stats I grabbed screenshots for the first round of benchmarking to see what the impact each stack/configuration would have on CPU and RAM usage. RAM Usage was fairly similar, but CPU Usage differed a lot.\nfig 6. Base System Metrics fig 7. PHP 7.2 Metrics fig 8. PHP 7.2 OpCache Enabled Metrics fig 9. PHP 7.2 OpCache Enabled Metrics, With W3TotalCache fig 10. PHP 7.2 OpCache Enabled Metrics, With Varnish fig 11. PHP 7.2 OpCache Enabled Metrics, With W3TotalCache and Varnish Random I found it interesting that W3TotalCache injected an HTML comment, which could be useful while debugging performance metrics for those of you heading down the W3TotalCache route.\nfig 12. W3TotalCache adds caching information in an HTML comment Addendum Time to Blog: 16h:15m ","permalink":"https://blog.mykro.co.nz/posts/2020-03-29-optimizing-wordpress/","summary":"Introduction WordPress is clearly one of the world\u0026rsquo;s most used Content Management Systems (CMS) commanding over 35% of the internet, and over 60% of the CMS market [1].\nWorking in Operations (ops), you see your fair share of friends, family and businesses that ask you to set up a WordPress site as their go to blogging platform. This really comes down to WordPress\u0026rsquo; ease of use, massive library of themes and it\u0026rsquo;s modular nature that enables the extension of it\u0026rsquo;s core via the use of plugins.","title":"Superfast WordPress"},{"content":"A while back, I met up with a friend where we started conversing about side projects and how we find it so hard to find the time and motivation to get into them. Moreover, how do we find our way into starting something and keeping at it? Yet, this felt like a rather common dilemma, as you can always find another \u0026rsquo;life hack\u0026rsquo; or \u0026lsquo;yet another self-help\u0026rsquo; book on the matter.\nFor example, I\u0026rsquo;ve been planning to build a static site based blog forever. Sadly though, much like my friend, we too often get stuck in drudgery. We need to have the right technology, the greatest ease of use, the most extensible tool.\nAs soon as you get into this mess, it feels like toil.\nSo, what is toil?\nAnd is toil a bad thing?\nIn the conversations we had, we talked a lot about static site generators and how amazing they are, but how we also find them a pain due to not having an out of the box GUI. We work all day at desk jobs where we consistently play around in our terminal. One of the last things we want to do is come home and feel like we are back at work living in our little black and green window.\nOften we see a new design, product or invention which is outstanding in its field, yet we don\u0026rsquo;t often see what it took to get \u0026lsquo;Product X\u0026rsquo; to where it is today. Quite often these products spend years on the threshing floor, designs being debated, with products potentially being thrown across the room in anger.\nIn looking at these examples, I\u0026rsquo;ve learnt that we sometimes are required to break into the monotonous to move forward. It can feel horrible and laborious until generally, the concept clicks and sticks in your head.\nSo coming back to our above questions, can we define toil?\nI\u0026rsquo;ve really enjoyed gaining a bird‚Äôs eye view of how things operate from a development and operations perspective at Google from their book on \u0026ldquo;Software Reliability Engineering\u0026rdquo;. Within, they take the time to define what they class as Toil in operating their services:\nToil is the kind of work tied to running a production service that tends to be manual, repetitive, automatable, tactical, devoid of enduring value, and that scales linearly as a service grows.\nWithin this definition, they list a set of attributes which tend to coincide with toil, two of which I‚Äôll pick up on: \u0026lsquo;repetitive\u0026rsquo; and \u0026rsquo; devoid of enduring value\u0026rsquo;.\nAnd so, here I was.\nWordpress, Wordpress.com, Blogger, Medium, Jeykll, Hugo.\nEach platform required, more or less, the same repetitive work - create an account, sign in, decide on a theme, upload media, tweak settings, attempt to write the first post. In hindsight, I guess this also coincided with not really having an aim to what I was trying to achieve. Each time the process led to finally having a platform, but each time my ‚Äòblog‚Äô was left in the same state as the last one, devoid of enduring value.\nOn re-reading about \u0026rsquo;toil\u0026rsquo; I realised, I needed to find something that ticks the boxes and stick with it. Remove the repetitive, valueless toil of playing around with multiple technologies and deliver.\nAnd so, stripping everything else away, I ended up with Hugo.\nSelf-contained single binary Markdown-based Static Site Generator An amazing minimalistic theme Deployable via Github pages Just ship it.\nAddendum I initially wrote and outlined this post on the 2018-08-28. It became bloated, focusing on too much (toil, time, energy, motivation and family commitments to name some of the headers). Coming to it tonight and remembering my goal here, I ended up removing the rest and shipped the Minimal Viable Product (MVP). In total, I have spent approximately 10 hours getting to this point.\n","permalink":"https://blog.mykro.co.nz/posts/2018-09-10-just-ship-it/","summary":"A while back, I met up with a friend where we started conversing about side projects and how we find it so hard to find the time and motivation to get into them. Moreover, how do we find our way into starting something and keeping at it? Yet, this felt like a rather common dilemma, as you can always find another \u0026rsquo;life hack\u0026rsquo; or \u0026lsquo;yet another self-help\u0026rsquo; book on the matter.","title":"Just Ship It"}]